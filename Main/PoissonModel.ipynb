{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # For saving and loading models\n",
    "\n",
    "base_data_path = '/Users/chris/MCM_2025_C/Main/'\n",
    "\n",
    "# 1. Correct File Loading\n",
    "medal_counts = pd.read_csv('/Users/chris/MCM_2025_C/Data/summerOly_medal_counts_with_codes.csv')\n",
    "programs = pd.read_csv('/Users/chris/MCM_2025_C/Data/summerOly_programs.csv')\n",
    "hosts = pd.read_csv('/Users/chris/MCM_2025_C/Data/summerOly_hosts_with_codes.csv')  # Corrected\n",
    "\n",
    "# 2. Load Athlete Counts Data\n",
    "pattern = os.path.join('/Users/chris/MCM_2025_C/Data/athlete_probabilities_by_year', '*.csv')\n",
    "athlete_files = glob.glob(pattern, recursive=True)\n",
    "athlete_dfs = []\n",
    "\n",
    "for file in athlete_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        # Standardize column names\n",
    "        df.rename(columns={\n",
    "            'bronze': 'Bronze',\n",
    "            'silver': 'Silver',\n",
    "            'gold': 'Gold',\n",
    "            'total_athletes': 'Total_Athletes',\n",
    "            'year': 'Year'\n",
    "        }, inplace=True)\n",
    "        # Extract Year from filename if 'Year' column is absent\n",
    "        if 'Year' not in df.columns:\n",
    "            year_str = os.path.splitext(os.path.basename(file))[0].split('_')[-1]\n",
    "            df['Year'] = int(year_str)\n",
    "        athlete_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Aggregate the athlete_probabilities_by_year DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate all athlete DataFrames\n",
    "athlete_counts = pd.concat(athlete_dfs, ignore_index=True)\n",
    "\n",
    "# 3. Aggregate Athlete Counts\n",
    "if 'Total_Athletes' in athlete_counts.columns:\n",
    "    athlete_counts_agg = athlete_counts.groupby(['Year', 'Country Code']).agg({\n",
    "        'Total_Athletes': 'sum'\n",
    "    }).reset_index()\n",
    "else:\n",
    "    # If 'Total_Athletes' is not present, count the number of athletes\n",
    "    athlete_counts_agg = athlete_counts.groupby(['Year', 'Country Code']).size().reset_index(name='Total_Athletes')\n",
    "\n",
    "\n",
    "# 4. Standardize Country Codes Across DataFrames\n",
    "def standardize_CountryCode(df, column='Country Code'):\n",
    "    df[column] = df[column].str.upper().str.strip()\n",
    "    return df\n",
    "\n",
    "medal_counts = standardize_CountryCode(medal_counts, 'Country Code')\n",
    "hosts = standardize_CountryCode(hosts, 'Country Code')        # Assuming hosts has 'Country Code'\n",
    "athlete_counts_agg = standardize_CountryCode(athlete_counts_agg, 'Country Code')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Aggregate the programs DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Programs DataFrame (Long Format):\n",
      "      Sport         Discipline Code Sports Governing Body  Year  Event_Count\n",
      "0  Aquatics  Artistic Swimming  SWA        World Aquatics  1896          0.0\n",
      "1  Aquatics             Diving  DIV        World Aquatics  1896          0.0\n",
      "2  Aquatics  Marathon Swimming  OWS        World Aquatics  1896          0.0\n",
      "3  Aquatics           Swimming  SWM        World Aquatics  1896          4.0\n",
      "4  Aquatics         Water Polo  WPO        World Aquatics  1896          0.0\n"
     ]
    }
   ],
   "source": [
    "# 2. Reshape 'programs' DataFrame from Wide to Long Format\n",
    "# Identify year columns (assuming they are all numeric)\n",
    "year_columns = [col for col in programs.columns if col.isdigit()]\n",
    "\n",
    "# Melt the DataFrame\n",
    "programs_long = programs.melt(\n",
    "    id_vars=['Sport', 'Discipline', 'Code', 'Sports Governing Body'],\n",
    "    value_vars=year_columns,\n",
    "    var_name='Year',\n",
    "    value_name='Event_Count'\n",
    ")\n",
    "\n",
    "# Convert 'Year' to integer\n",
    "programs_long['Year'] = programs_long['Year'].astype(int)\n",
    "\n",
    "# Preview the reshaped DataFrame\n",
    "print(\"Reshaped Programs DataFrame (Long Format):\")\n",
    "print(programs_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Event Data per Year:\n",
      "   Year  Total_Events  Number_of_Sports\n",
      "0  1896         107.0                51\n",
      "1  1900         236.0                51\n",
      "2  1904         224.0                51\n",
      "3  1906         176.0                51\n",
      "4  1908         267.0                51\n"
     ]
    }
   ],
   "source": [
    "# 3. Aggregate Event Counts and Number of Sports per Year\n",
    "event_agg = programs_long.groupby('Year').agg(\n",
    "    Total_Events=('Event_Count', 'sum'),\n",
    "    Number_of_Sports=('Sport', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Preview the aggregated data\n",
    "print(\"Aggregated Event Data per Year:\")\n",
    "print(event_agg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge All DataFrames into merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Medal Counts with Athlete Counts successfully.\n"
     ]
    }
   ],
   "source": [
    "if not medal_counts.empty and not athlete_counts_agg.empty:\n",
    "    merged_df = pd.merge(\n",
    "        medal_counts,\n",
    "        athlete_counts_agg,\n",
    "        on=['Year', 'Country Code'],\n",
    "        how='left'\n",
    "    )\n",
    "    print(\"\\nMerged Medal Counts with Athlete Counts successfully.\")\n",
    "else:\n",
    "    merged_df = medal_counts.copy()\n",
    "    merged_df['Total_Athletes'] = 0\n",
    "    print(\"\\nAthlete Counts Aggregated DataFrame is empty. 'Total_Athletes' set to 0 in merged_df.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Total_Athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Total_Athletes' missing values filled with 0.\n"
     ]
    }
   ],
   "source": [
    "if 'Total_Athletes' in merged_df.columns:\n",
    "    merged_df['Total_Athletes'] = merged_df['Total_Athletes'].fillna(0).astype(int)\n",
    "    print(\"'Total_Athletes' missing values filled with 0.\")\n",
    "else:\n",
    "    merged_df['Total_Athletes'] = 0\n",
    "    print(\"'Total_Athletes' column not found. Created and set to 0.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with hosts DataFrame to Set Is_Host Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Is_Host' indicator set successfully.\n"
     ]
    }
   ],
   "source": [
    "if not hosts.empty:\n",
    "    # Assuming 'hosts' DataFrame has 'Year' and 'Country Code' indicating the host country each year\n",
    "    host_info = set(hosts[['Year', 'Country Code']].drop_duplicates().itertuples(index=False, name=None))\n",
    "    \n",
    "    # Create 'Is_Host' column\n",
    "    merged_df['Is_Host'] = merged_df.apply(\n",
    "        lambda row: 1 if (row['Year'], row['Country Code']) in host_info else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    print(\"'Is_Host' indicator set successfully.\")\n",
    "else:\n",
    "    merged_df['Is_Host'] = 0\n",
    "    print(\"Hosts DataFrame is empty. 'Is_Host' set to 0.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Aggregated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged with Aggregated Event Data successfully.\n",
      "Unique countries: 152\n",
      "Total rows in merged_df: 1419\n",
      "Warning: There are duplicate Country Code entries. Aggregating data to ensure one row per country.\n",
      "Data aggregated to have one row per country.\n",
      "\n",
      "Final Merged DataFrame:\n",
      "  Country Code  Total  Total_Athletes  Is_Host  Number_of_Sports  Total_Events\n",
      "0          AFG      2              48        0               102          1343\n",
      "1          AHO      1              32        0                51           528\n",
      "2          ALB      2              26        0                51           738\n",
      "3          ALG     20             656        0               408          5099\n",
      "4          ANZ     12              40        0               102           503\n"
     ]
    }
   ],
   "source": [
    "if not event_agg.empty:\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        event_agg,\n",
    "        on='Year',\n",
    "        how='left'\n",
    "    )\n",
    "    # Fill missing values with 0\n",
    "    merged_df['Total_Events'] = merged_df['Total_Events'].fillna(0).astype(int)\n",
    "    merged_df['Number_of_Sports'] = merged_df['Number_of_Sports'].fillna(0).astype(int)\n",
    "    print(\"Merged with Aggregated Event Data successfully.\")\n",
    "else:\n",
    "    merged_df['Total_Events'] = 0\n",
    "    merged_df['Number_of_Sports'] = 0\n",
    "    print(\"Aggregated Event Data is empty. 'Total_Events' and 'Number_of_Sports' set to 0.\")\n",
    "\n",
    "\n",
    "# merged_df['Athletes_per_Event'] = merged_df['Total_Athletes'] / merged_df['Total_Events'].replace(0, 1)  # Avoid division by zero\n",
    "# Check for unique Country Code\n",
    "unique_countries = merged_df['Country Code'].nunique()\n",
    "total_rows = merged_df.shape[0]\n",
    "print(f\"Unique countries: {unique_countries}\")\n",
    "print(f\"Total rows in merged_df: {total_rows}\")\n",
    "\n",
    "if unique_countries != total_rows:\n",
    "    print(\"Warning: There are duplicate Country Code entries. Aggregating data to ensure one row per country.\")\n",
    "    # Aggregate data (e.g., sum of features) to have one row per country\n",
    "    merged_df = merged_df.groupby('Country Code').agg({\n",
    "        'Total': 'sum',\n",
    "        'Total_Athletes': 'sum',\n",
    "        'Is_Host': 'max',  # Assuming Is_Host is binary (0 or 1)\n",
    "        'Number_of_Sports': 'sum',\n",
    "        'Total_Events': 'sum',\n",
    "        # Add other relevant features as needed\n",
    "    }).reset_index()\n",
    "    print(\"Data aggregated to have one row per country.\")\n",
    "else:\n",
    "    print(\"All Country Code entries are unique.\")\n",
    "\n",
    "\n",
    "print(\"\\nFinal Merged DataFrame:\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables for Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependent variable set to 'Total'.\n"
     ]
    }
   ],
   "source": [
    "# Define the dependent variable\n",
    "dependent_var = 'Total'  # This is the total medal count\n",
    "\n",
    "# Verify if 'Total' exists in merged_df\n",
    "if dependent_var not in merged_df.columns:\n",
    "    print(f\"Error: Dependent variable '{dependent_var}' not found in merged_df.\")\n",
    "    # Optionally, inspect available columns\n",
    "    print(\"Available columns:\", merged_df.columns.tolist())\n",
    "else:\n",
    "    print(f\"\\nDependent variable set to '{dependent_var}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All independent variables are present in merged_df.\n"
     ]
    }
   ],
   "source": [
    "# Define the list of independent variables\n",
    "independent_vars = ['Total_Athletes', 'Is_Host', 'Number_of_Sports', 'Total_Events']\n",
    "\n",
    "# Verify if all independent variables exist in merged_df\n",
    "missing_vars = [var for var in independent_vars if var not in merged_df.columns]\n",
    "if missing_vars:\n",
    "    print(f\"Warning: The following independent variables are missing in merged_df: {missing_vars}\")\n",
    "    # Handle missing variables, e.g., create them with default values\n",
    "    for var in missing_vars:\n",
    "        merged_df[var] = 0\n",
    "    print(f\"Missing independent variables {missing_vars} created with default value 0.\")\n",
    "else:\n",
    "    print(\"All independent variables are present in merged_df.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame saved successfully to /Users/chris/MCM_2025_C/Data/merged_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Define the output path\n",
    "output_path = '/Users/chris/MCM_2025_C/Data/merged_data.csv'\n",
    "\n",
    "# Save merged_df to CSV\n",
    "try:\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nMerged DataFrame saved successfully to {output_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving merged DataFrame to CSV: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in X:\n",
      "Total_Athletes      0\n",
      "Is_Host             0\n",
      "Number_of_Sports    0\n",
      "Total_Events        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in y:\n",
      "0\n",
      "\n",
      "Data split into training and testing sets successfully.\n"
     ]
    }
   ],
   "source": [
    "X = merged_df[independent_vars]\n",
    "y = merged_df[dependent_var]\n",
    "\n",
    "# Check for missing values in X and y\n",
    "print(\"\\nMissing values in X:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in y:\")\n",
    "print(y.isnull().sum())\n",
    "\n",
    "# Handle missing values if any\n",
    "if X.isnull().values.any():\n",
    "    X = X.fillna(X.median())\n",
    "    print(\"Missing values in X filled with median.\")\n",
    "\n",
    "if y.isnull().values.any():\n",
    "    y = y.fillna(0)\n",
    "    print(\"Missing values in y filled with 0.\")\n",
    "\n",
    "# Split the data (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nData split into training and testing sets successfully.\")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling applied successfully.\n"
     ]
    }
   ],
   "source": [
    "# 10. Feature Scaling (If Needed)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling applied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained Random Forest model for future use\n",
    "joblib.dump(rf_model, os.path.join(base_data_path, 'random_forest_model.pkl'))\n",
    "print(\"Random Forest Regressor trained and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train the Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29     1\n",
      "22     1\n",
      "51     1\n",
      "75     1\n",
      "11     1\n",
      "      ..\n",
      "71     1\n",
      "106    1\n",
      "14     1\n",
      "92     1\n",
      "102    1\n",
      "Name: Total, Length: 121, dtype: int64\n",
      "29       4\n",
      "22     354\n",
      "51     981\n",
      "75      78\n",
      "11       1\n",
      "      ... \n",
      "71     663\n",
      "106     18\n",
      "14       2\n",
      "92       2\n",
      "102     11\n",
      "Name: Total, Length: 121, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m logreg \u001b[38;5;241m=\u001b[39m LogisticRegression(multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mlogreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Save the trained Logistic Regression model for future use\u001b[39;00m\n\u001b[1;32m     13\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(logreg, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_regression_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "# Create a binary target: 1 if the country won at least one medal, 0 otherwise\n",
    "y_train_binary = (y_train > 0).astype(int)\n",
    "print(y_train_binary)\n",
    "print(y_train)\n",
    "\n",
    "# Initialize Multinomial Logistic Regression\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg.fit(X_train, y_train_binary)\n",
    "\n",
    "# Save the trained Logistic Regression model for future use\n",
    "joblib.dump(logreg, os.path.join(base_data_path, 'logistic_regression_model.pkl'))\n",
    "print(\"Logistic Regression model trained and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2028 Athlete and Event Data\n",
    "athletes_2028_path = os.path.join(base_data_path, 'athletes_2028.csv')\n",
    "athletes_2028 = pd.read_csv(athletes_2028_path)\n",
    "\n",
    "# Standardize 'Country_Code'\n",
    "athletes_2028 = standardize_country_code(athletes_2028, 'Country_Code')\n",
    "\n",
    "# Select Features for Prediction\n",
    "X_2028 = athletes_2028[independent_vars]\n",
    "\n",
    "# Load New Countries Data\n",
    "new_countries_2028_path = os.path.join(base_data_path, 'new_countries_2028.csv')\n",
    "new_countries_2028 = pd.read_csv(new_countries_2028_path)\n",
    "\n",
    "# Standardize 'Country_Code' in New Countries Data\n",
    "new_countries_2028 = standardize_country_code(new_countries_2028, 'Country_Code')\n",
    "\n",
    "# Select Features for New Countries\n",
    "X_new_2028 = new_countries_2028[independent_vars]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale Features and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler (ensure it's the same scaler used during training)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Fit on training data\n",
    "\n",
    "# Transform the 2028 data\n",
    "X_2028_scaled = scaler.transform(X_2028)\n",
    "X_new_2028_scaled = scaler.transform(X_new_2028)\n",
    "\n",
    "\n",
    "# Load the trained Random Forest model\n",
    "rf_model = joblib.load(os.path.join(base_data_path, 'random_forest_model.pkl'))\n",
    "\n",
    "# Load the trained Logistic Regression model\n",
    "logreg = joblib.load(os.path.join(base_data_path, 'logistic_regression_model.pkl'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Medal Counts for 2028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict total medals for each country in 2028\n",
    "predicted_medals_2028 = rf_model.predict(X_2028_scaled)\n",
    "\n",
    "# Assign predictions to the 2028 DataFrame\n",
    "athletes_2028['Predicted_Medals'] = predicted_medals_2028.round().astype(int)\n",
    "\n",
    "# Predict probability of winning at least one medal for new countries\n",
    "new_countries_proba = logreg.predict_proba(X_new_2028_scaled)[:, 1]\n",
    "\n",
    "# Combine predictions with new countries data\n",
    "new_countries_2028['Medal_Probability'] = new_countries_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allocate All Medals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'athletes_2028' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m total_medals_2028 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# Replace with actual total\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Sum of predicted medals from Random Forest\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m sum_pred_medals \u001b[38;5;241m=\u001b[39m \u001b[43mathletes_2028\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Medals\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Normalize predictions to match the total medals\u001b[39;00m\n\u001b[1;32m      8\u001b[0m athletes_2028[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormalized_Medals\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m athletes_2028[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Medals\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (total_medals_2028 \u001b[38;5;241m/\u001b[39m sum_pred_medals)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'athletes_2028' is not defined"
     ]
    }
   ],
   "source": [
    "# Define total medals to be awarded in 2028\n",
    "total_medals_2028 = 1000  # Replace with actual total\n",
    "\n",
    "# Sum of predicted medals from Random Forest\n",
    "sum_pred_medals = athletes_2028['Predicted_Medals'].sum()\n",
    "\n",
    "# Normalize predictions to match the total medals\n",
    "athletes_2028['Normalized_Medals'] = athletes_2028['Predicted_Medals'] * (total_medals_2028 / sum_pred_medals)\n",
    "\n",
    "# Round to integer medal counts\n",
    "athletes_2028['Normalized_Medals'] = athletes_2028['Normalized_Medals'].round().astype(int)\n",
    "\n",
    "# Assign normalized medals\n",
    "athletes_2028['Predicted_Medals'] = athletes_2028['Normalized_Medals']\n",
    "athletes_2028.drop('Normalized_Medals', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Number of new medals to allocate (e.g., 50)\n",
    "new_medals = 50  # Adjust based on strategy\n",
    "\n",
    "# Sort new countries by their medal probability in descending order\n",
    "new_countries_sorted = new_countries_2028.sort_values(by='Medal_Probability', ascending=False)\n",
    "\n",
    "# Normalize probabilities\n",
    "total_prob_new = new_countries_sorted['Medal_Probability'].sum()\n",
    "\n",
    "# Calculate assigned medals based on probabilities\n",
    "new_countries_sorted['Assigned_Medals'] = (new_countries_sorted['Medal_Probability'] / total_prob_new * new_medals).round().astype(int)\n",
    "\n",
    "# Assign medals to new countries\n",
    "for idx, row in new_countries_sorted.iterrows():\n",
    "    new_entry = {\n",
    "        'Country_Code': row['Country_Code'],\n",
    "        'Predicted_Medals': row['Assigned_Medals']\n",
    "    }\n",
    "    athletes_2028 = athletes_2028.append(new_entry, ignore_index=True)\n",
    "\n",
    "print(\"\\nAssigned Medals to New Countries:\")\n",
    "print(new_countries_sorted[['Country_Code', 'Assigned_Medals']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total predicted medals\n",
    "total_predicted_medals = athletes_2028['Predicted_Medals'].sum()\n",
    "\n",
    "# Check if it matches the total medals\n",
    "if total_predicted_medals != total_medals_2028:\n",
    "    difference = total_medals_2028 - total_predicted_medals\n",
    "    print(f\"\\nAdjusting medal counts by {difference} to match the total medals.\")\n",
    "    \n",
    "    # Add/subtract the difference to/from the country with the highest predicted medals\n",
    "    if difference > 0:\n",
    "        idx_max = athletes_2028['Predicted_Medals'].idxmax()\n",
    "        athletes_2028.at[idx_max, 'Predicted_Medals'] += difference\n",
    "    else:\n",
    "        idx_max = athletes_2028['Predicted_Medals'].idxmax()\n",
    "        athletes_2028.at[idx_max, 'Predicted_Medals'] += difference  # difference is negative\n",
    "    \n",
    "    print(f\"Adjusted Total Predicted Medals: {athletes_2028['Predicted_Medals'].sum()}\")\n",
    "else:\n",
    "    print(\"\\nAll medals have been successfully distributed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final predictions to a new CSV\n",
    "final_predictions_path = '/Users/chris/MCM_2025_C/Mainmedal_count_2028_predictions.csv'\n",
    "athletes_2028[['Country_Code', 'Predicted_Medals']].to_csv(final_predictions_path, index=False)\n",
    "print(f\"\\nFinal medal predictions for 2028 saved to {final_predictions_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
