{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load and Integrate Data\n",
    "def load_and_concatenate_data(folder_path):\n",
    "    \"\"\"\n",
    "    Load all CSV files from the specified folder, extract the year from filename,\n",
    "    and concatenate into a single DataFrame.\n",
    "    \"\"\"\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    df_list = []\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            year_str = os.path.basename(file).split('.')[0]\n",
    "            year = int(year_str)  # Extract year from filename\n",
    "        except ValueError:\n",
    "            print(f\"Filename {file} does not start with a valid year. Skipping.\")\n",
    "            continue\n",
    "        temp_df = pd.read_csv(file, usecols=['Country Code', 'Gender', 'Event', 'bronze', 'silver', 'gold', 'total athletes'])\n",
    "        temp_df['Year'] = year\n",
    "        df_list.append(temp_df)\n",
    "    if not df_list:\n",
    "        raise ValueError(\"No valid CSV files found in the directory.\")\n",
    "    concatenated_df = pd.concat(df_list, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "# 2. Preprocess Data\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame:\n",
    "    - Handle missing values\n",
    "    - Ensure categorical columns are strings\n",
    "    - Encode categorical variables\n",
    "    - Create composite target score\n",
    "    \"\"\"\n",
    "    # Fill missing values with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Define categorical features\n",
    "    categorical_features = ['Country Code', 'Gender', 'Event']\n",
    "    \n",
    "    # Ensure all categorical features are strings to prevent mixed types\n",
    "    for col in categorical_features:\n",
    "        df[col] = df[col].astype(str)\n",
    "    \n",
    "    # Initialize OneHotEncoder with updated parameter\n",
    "    try:\n",
    "        encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    except TypeError:\n",
    "        # For scikit-learn versions < 1.2\n",
    "        encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    \n",
    "    encoded_cats = encoder.fit_transform(df[categorical_features])\n",
    "    encoded_cat_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out(categorical_features))\n",
    "    \n",
    "    # Concatenate encoded features with the original DataFrame\n",
    "    df = pd.concat([df.reset_index(drop=True), encoded_cat_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # Drop original categorical columns\n",
    "    df.drop(columns=categorical_features, inplace=True)\n",
    "    \n",
    "    # Rename 'total athletes' to 'total_athletes' for consistency\n",
    "    if 'total athletes' in df.columns:\n",
    "        df.rename(columns={'total athletes': 'total_athletes'}, inplace=True)\n",
    "    \n",
    "    # Create composite target score: Gold=3, Silver=2, Bronze=1\n",
    "    df['Medal_Score'] = (df['gold'] * 3) + (df['silver'] * 2) + (df['bronze'] * 1)\n",
    "    \n",
    "    return df, encoder\n",
    "\n",
    "# 3. Train Model\n",
    "def train_model(X, y):\n",
    "    \"\"\"\n",
    "    Train a RandomForestRegressor with Time Series Cross-Validation.\n",
    "    Returns the trained model.\n",
    "    \"\"\"\n",
    "    # Initialize TimeSeriesSplit with fewer splits to reduce runtime\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    # Initialize RandomForestRegressor with n_jobs=-1 to utilize all cores\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    rmse_scores = []\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    # Cross-validation\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        rf.fit(X_train_cv, y_train_cv)\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_pred_cv = rf.predict(X_test_cv)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = mean_squared_error(y_test_cv, y_pred_cv, squared=False)\n",
    "        mae = mean_absolute_error(y_test_cv, y_pred_cv)\n",
    "        r2 = r2_score(y_test_cv, y_pred_cv)\n",
    "        \n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "        r2_scores.append(r2)\n",
    "    \n",
    "    # Print cross-validation metrics\n",
    "    print(f\"Cross-validated RMSE: {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")\n",
    "    print(f\"Cross-validated MAE: {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "    print(f\"Cross-validated R²: {np.mean(r2_scores):.2f} ± {np.std(r2_scores):.2f}\")\n",
    "    \n",
    "    # Fit the model on the entire dataset\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    return rf\n",
    "\n",
    "# 4. Evaluate on Training Data\n",
    "def evaluate_on_training(model, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the training data.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    print(f\"Training RMSE: {rmse:.2f}\")\n",
    "    print(f\"Training MAE: {mae:.2f}\")\n",
    "    print(f\"Training R²: {r2:.2f}\")\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# 5. Plotting Functions\n",
    "def plot_actual_vs_predicted(y_true, y_pred, title=\"Actual vs. Predicted Medal Scores\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.6)\n",
    "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')  # Diagonal line\n",
    "    plt.xlabel(\"Actual Medal Score\")\n",
    "    plt.ylabel(\"Predicted Medal Score\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_residuals(y_true, y_pred, title=\"Residuals Plot\"):\n",
    "    residuals = y_true - y_pred\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(residuals, kde=True, bins=30)\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importances(model, feature_names, top_n=10, title=\"Top Feature Importances\"):\n",
    "    importances = model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    feature_importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(top_n))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Importance Score\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 6. Predict and Allocate Medals (Vectorized)\n",
    "def predict_and_allocate_medals_vectorized(model, encoder, folder_path, target_year=2028):\n",
    "    \"\"\"\n",
    "    Predict medal scores for the target year and allocate Gold, Silver, Bronze medals per event using vectorized operations.\n",
    "    \"\"\"\n",
    "    # Load target year data\n",
    "    target_file = os.path.join(folder_path, f\"{target_year}.csv\")\n",
    "    if not os.path.exists(target_file):\n",
    "        raise FileNotFoundError(f\"{target_file} does not exist.\")\n",
    "    \n",
    "    target_df = pd.read_csv(target_file, usecols=['Country Code', 'Gender', 'Event', 'bronze', 'silver', 'gold', 'total athletes'])\n",
    "    target_df['Year'] = target_year\n",
    "    \n",
    "    # Fill missing values with 0\n",
    "    target_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Define categorical features\n",
    "    categorical_features = ['Country Code', 'Gender', 'Event']\n",
    "    \n",
    "    # Ensure all categorical features are strings\n",
    "    for col in categorical_features:\n",
    "        target_df[col] = target_df[col].astype(str)\n",
    "    \n",
    "    # Encode categorical variables using the same encoder\n",
    "    try:\n",
    "        encoded_cats = encoder.transform(target_df[categorical_features])\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error during encoding: {ve}\")\n",
    "        raise\n",
    "    \n",
    "    encoded_cat_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out(categorical_features))\n",
    "    \n",
    "    # Concatenate encoded features with the original DataFrame\n",
    "    target_df = pd.concat([target_df.reset_index(drop=True), encoded_cat_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # Drop original categorical columns\n",
    "    target_df.drop(columns=categorical_features, inplace=True)\n",
    "    \n",
    "    # Rename 'total athletes' to 'total_athletes' for consistency\n",
    "    if 'total athletes' in target_df.columns:\n",
    "        target_df.rename(columns={'total athletes': 'total_athletes'}, inplace=True)\n",
    "    \n",
    "    # Define feature columns (ensure they match training features)\n",
    "    feature_cols = ['total_athletes'] + list(encoded_cat_df.columns)\n",
    "    missing_features = set(feature_cols) - set(target_df.columns)\n",
    "    if missing_features:\n",
    "        # Add missing feature columns with default value 0\n",
    "        for feature in missing_features:\n",
    "            target_df[feature] = 0\n",
    "        print(f\"Added missing features: {missing_features}\")\n",
    "    \n",
    "    X_target = target_df[feature_cols]\n",
    "    \n",
    "    # Predict Medal_Score\n",
    "    target_df['Predicted_Score'] = model.predict(X_target)\n",
    "    \n",
    "    # Sort by Event and Predicted_Score\n",
    "    target_df_sorted = target_df.sort_values(['Event', 'Predicted_Score'], ascending=[True, False])\n",
    "    \n",
    "    # Assign ranks within each event\n",
    "    target_df_sorted['Rank'] = target_df_sorted.groupby('Event')['Predicted_Score'].rank(method='first', ascending=False)\n",
    "    \n",
    "    # Assign medals based on rank\n",
    "    medal_assignments_df = target_df_sorted[target_df_sorted['Rank'] <= 3].copy()\n",
    "    medal_assignments_df['Medal'] = medal_assignments_df['Rank'].map({1: 'Gold', 2: 'Silver', 3: 'Bronze'})\n",
    "    \n",
    "    # Select relevant columns\n",
    "    medal_assignments_df = medal_assignments_df[['Year', 'Event', 'Medal', 'Country Code']]\n",
    "    \n",
    "    # Rename for consistency\n",
    "    medal_assignments_df.rename(columns={'Country Code': 'Country_Code'}, inplace=True)\n",
    "    \n",
    "    return medal_assignments_df\n",
    "\n",
    "# 7. Additional Plot: Medal Distribution per Country\n",
    "def plot_medal_distribution(allocations_df):\n",
    "    \"\"\"\n",
    "    Plot the number of Gold, Silver, and Bronze medals per country.\n",
    "    \"\"\"\n",
    "    medal_counts = allocations_df.groupby(['Country_Code', 'Medal']).size().reset_index(name='Count')\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Count', y='Country_Code', hue='Medal', data=medal_counts)\n",
    "    plt.title(\"Medal Distribution per Country for 2028 Olympics\")\n",
    "    plt.xlabel(\"Number of Medals\")\n",
    "    plt.ylabel(\"Country Code\")\n",
    "    plt.legend(title='Medal Type')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 8. Main Execution\n",
    "def main():\n",
    "    data_folder = \"/Users/chris/MCM_2025_C/Data/data_by_year_merged\"  # Path to your data folder\n",
    "    target_year = 2028\n",
    "    \n",
    "    # Load and concatenate data\n",
    "    try:\n",
    "        data = load_and_concatenate_data(data_folder)\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error loading data: {ve}\")\n",
    "        return\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_df, encoder = preprocess_data(data)\n",
    "    \n",
    "    # Define features and target\n",
    "    # Exclude non-feature columns: 'gold', 'silver', 'bronze', 'Medal_Score', 'Year'\n",
    "    non_feature_cols = ['gold', 'silver', 'bronze', 'Medal_Score', 'Year']\n",
    "    feature_cols = [col for col in processed_df.columns if col not in non_feature_cols]\n",
    "    \n",
    "    X = processed_df[feature_cols]\n",
    "    y = processed_df['Medal_Score']\n",
    "    \n",
    "    # Sort data chronologically if 'Year' exists\n",
    "    if 'Year' in processed_df.columns:\n",
    "        sorted_indices = processed_df['Year'].argsort()\n",
    "        X_sorted = X.iloc[sorted_indices]\n",
    "        y_sorted = y.iloc[sorted_indices]\n",
    "    else:\n",
    "        X_sorted = X\n",
    "        y_sorted = y\n",
    "    \n",
    "    # Train model\n",
    "    model = train_model(X_sorted, y_sorted)\n",
    "    \n",
    "    # Evaluate on training data\n",
    "    y_train_pred = model.predict(X_sorted)\n",
    "    rmse_train = mean_squared_error(y_sorted, y_train_pred, squared=False)\n",
    "    mae_train = mean_absolute_error(y_sorted, y_train_pred)\n",
    "    r2_train = r2_score(y_sorted, y_train_pred)\n",
    "    \n",
    "    print(f\"Training RMSE: {rmse_train:.2f}\")\n",
    "    print(f\"Training MAE: {mae_train:.2f}\")\n",
    "    print(f\"Training R²: {r2_train:.2f}\")\n",
    "    \n",
    "    # Plot Actual vs. Predicted\n",
    "    plot_actual_vs_predicted(y_sorted, y_train_pred, title=\"Training Data: Actual vs. Predicted Medal Scores\")\n",
    "    \n",
    "    # Plot Residuals\n",
    "    plot_residuals(y_sorted, y_train_pred, title=\"Training Data: Residuals Plot\")\n",
    "    \n",
    "    # Plot Feature Importances\n",
    "    plot_feature_importances(model, feature_cols, top_n=10, title=\"Top 10 Feature Importances\")\n",
    "    \n",
    "    # Predict and allocate medals for the target year using vectorized allocation\n",
    "    try:\n",
    "        allocations = predict_and_allocate_medals_vectorized(model, encoder, data_folder, target_year)\n",
    "    except FileNotFoundError as fnfe:\n",
    "        print(fnfe)\n",
    "        return\n",
    "    except ValueError as ve:\n",
    "        print(f\"Value Error: {ve}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Display the first 20 medal assignments\n",
    "    print(\"\\nMedal Assignments Preview:\")\n",
    "    print(allocations.head(20))\n",
    "    \n",
    "    # Save the allocations to a CSV file\n",
    "    output_file = f\"medal_allocations_{target_year}.csv\"\n",
    "    allocations.to_csv(output_file, index=False)\n",
    "    print(f\"\\nMedal allocations for {target_year} saved to '{output_file}'.\")\n",
    "    \n",
    "    # Plot Medal Distribution per Country\n",
    "    plot_medal_distribution(allocations)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
